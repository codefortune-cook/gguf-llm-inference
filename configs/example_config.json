{
  "model": {
    "n_ctx": 4096,
    "n_threads": -1,
    "n_gpu_layers": 0,
    "verbose": false
  },
  "generation": {
    "max_tokens": 512,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 40,
    "repeat_penalty": 1.1,
    "stream": false
  },
  "chat": {
    "system_prompt": "You are a helpful AI assistant.",
    "stop_sequences": ["\nUser:", "\nHuman:", "\n###"]
  }
}